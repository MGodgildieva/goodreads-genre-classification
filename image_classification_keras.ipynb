{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import urllib.request as req\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hamming loss\n",
    "def hn_multilabel_loss(y_true, y_pred):\n",
    "    # Avoid divide by 0\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Multi-task loss\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(dataframe,out_folder):\n",
    "    ids = dataframe.index.values\n",
    "    for image_id in ids:\n",
    "        url = dataframe.loc[image_id]['image_url']\n",
    "        if os.path.isfile(out_folder + '/' + str(image_id) + '.jpg') == False:\n",
    "            r = req.urlretrieve(url, out_folder + '/' + str(image_id) + '.jpg')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_image_name_col(df):\n",
    "    ids = df.index.values\n",
    "    names = []\n",
    "    for i in ids:\n",
    "        names.append(str(i)+'.jpg')\n",
    "    return np.array(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training set\n",
    "pickle_in_train = open(\"all_books_train.pickle\",\"rb\")\n",
    "train = pickle.load(pickle_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test set\n",
    "pickle_in_test = open(\"all_books_test.pickle\",\"rb\")\n",
    "test = pickle.load(pickle_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36389, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12131, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_edition</th>\n",
       "      <th>book_format</th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>book_pages</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_rating_count</th>\n",
       "      <th>book_review_count</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>image_url</th>\n",
       "      <th>genres_list</th>\n",
       "      <th>genres_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>Nicole Jacquelyn</td>\n",
       "      <td>\"How is it, that someone can make decision aft...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305 pages</td>\n",
       "      <td>4.02</td>\n",
       "      <td>17962</td>\n",
       "      <td>1159</td>\n",
       "      <td>Craving Constellations</td>\n",
       "      <td>Romance|Romance|Contemporary Romance|Contemporary</td>\n",
       "      <td>https://images.gr-assets.com/books/1377563339l...</td>\n",
       "      <td>[Romance, Contemporary, Contemporary Romance]</td>\n",
       "      <td>[Romance, Contemporary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19880</th>\n",
       "      <td>Adam Schell</td>\n",
       "      <td>A village in Tuscany is the setting for this j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78039E+12</td>\n",
       "      <td>340 pages</td>\n",
       "      <td>3.74</td>\n",
       "      <td>646</td>\n",
       "      <td>161</td>\n",
       "      <td>Tomato Rhapsody: A Fable of Love, Lust &amp; Forbi...</td>\n",
       "      <td>Fiction|Historical|Historical Fiction|Cultural...</td>\n",
       "      <td>https://images.gr-assets.com/books/1320422913l...</td>\n",
       "      <td>[Historical Fiction, Fiction, Food and Drink, ...</td>\n",
       "      <td>[Fiction, Romance, Historical, Cultural]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>Robert Moss</td>\n",
       "      <td>Have you ever said something was “only a dream...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78158E+12</td>\n",
       "      <td>224 pages</td>\n",
       "      <td>4.04</td>\n",
       "      <td>345</td>\n",
       "      <td>41</td>\n",
       "      <td>The Three \"Only\" Things: Tapping the Power of ...</td>\n",
       "      <td>Nonfiction|Spirituality|Psychology|Spiritualit...</td>\n",
       "      <td>https://images.gr-assets.com/books/1328746102l...</td>\n",
       "      <td>[Nonfiction, New Age, Psychology, Spirituality]</td>\n",
       "      <td>[Nonfiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>David Ambrose</td>\n",
       "      <td>A train of seemingly random events - coinciden...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Binding</td>\n",
       "      <td>9.78074E+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.35</td>\n",
       "      <td>166</td>\n",
       "      <td>18</td>\n",
       "      <td>Coincidence</td>\n",
       "      <td>Fiction|Suspense|Historical|Science Fiction|My...</td>\n",
       "      <td>https://images.gr-assets.com/books/1408924887l...</td>\n",
       "      <td>[Suspense, Fiction, Mystery, Historical, Scien...</td>\n",
       "      <td>[Fiction, Mystery, Historical, Science Fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>Richard North Patterson</td>\n",
       "      <td>When the body of eleven-year-old Thuy Sen is f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78035E+12</td>\n",
       "      <td>463 pages</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2400</td>\n",
       "      <td>154</td>\n",
       "      <td>Conviction</td>\n",
       "      <td>Fiction|Mystery|Thriller|Legal Thriller|Thriller</td>\n",
       "      <td>https://images.gr-assets.com/books/1399495278l...</td>\n",
       "      <td>[Thriller, Legal Thriller, Fiction, Mystery]</td>\n",
       "      <td>[Thriller, Fiction, Mystery]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  book_authors  \\\n",
       "6377          Nicole Jacquelyn   \n",
       "19880              Adam Schell   \n",
       "23352              Robert Moss   \n",
       "16021            David Ambrose   \n",
       "49981  Richard North Patterson   \n",
       "\n",
       "                                               book_desc book_edition  \\\n",
       "6377   \"How is it, that someone can make decision aft...          NaN   \n",
       "19880  A village in Tuscany is the setting for this j...          NaN   \n",
       "23352  Have you ever said something was “only a dream...          NaN   \n",
       "16021  A train of seemingly random events - coinciden...          NaN   \n",
       "49981  When the body of eleven-year-old Thuy Sen is f...          NaN   \n",
       "\n",
       "           book_format    book_isbn book_pages  book_rating  \\\n",
       "6377    Kindle Edition          NaN  305 pages         4.02   \n",
       "19880        Hardcover  9.78039E+12  340 pages         3.74   \n",
       "23352        Hardcover  9.78158E+12  224 pages         4.04   \n",
       "16021  Unknown Binding  9.78074E+12        NaN         3.35   \n",
       "49981        Hardcover  9.78035E+12  463 pages         3.89   \n",
       "\n",
       "       book_rating_count  book_review_count  \\\n",
       "6377               17962               1159   \n",
       "19880                646                161   \n",
       "23352                345                 41   \n",
       "16021                166                 18   \n",
       "49981               2400                154   \n",
       "\n",
       "                                              book_title  \\\n",
       "6377                              Craving Constellations   \n",
       "19880  Tomato Rhapsody: A Fable of Love, Lust & Forbi...   \n",
       "23352  The Three \"Only\" Things: Tapping the Power of ...   \n",
       "16021                                        Coincidence   \n",
       "49981                                         Conviction   \n",
       "\n",
       "                                                  genres  \\\n",
       "6377   Romance|Romance|Contemporary Romance|Contemporary   \n",
       "19880  Fiction|Historical|Historical Fiction|Cultural...   \n",
       "23352  Nonfiction|Spirituality|Psychology|Spiritualit...   \n",
       "16021  Fiction|Suspense|Historical|Science Fiction|My...   \n",
       "49981   Fiction|Mystery|Thriller|Legal Thriller|Thriller   \n",
       "\n",
       "                                               image_url  \\\n",
       "6377   https://images.gr-assets.com/books/1377563339l...   \n",
       "19880  https://images.gr-assets.com/books/1320422913l...   \n",
       "23352  https://images.gr-assets.com/books/1328746102l...   \n",
       "16021  https://images.gr-assets.com/books/1408924887l...   \n",
       "49981  https://images.gr-assets.com/books/1399495278l...   \n",
       "\n",
       "                                             genres_list  \\\n",
       "6377       [Romance, Contemporary, Contemporary Romance]   \n",
       "19880  [Historical Fiction, Fiction, Food and Drink, ...   \n",
       "23352    [Nonfiction, New Age, Psychology, Spirituality]   \n",
       "16021  [Suspense, Fiction, Mystery, Historical, Scien...   \n",
       "49981       [Thriller, Legal Thriller, Fiction, Mystery]   \n",
       "\n",
       "                                            genres_cut  \n",
       "6377                           [Romance, Contemporary]  \n",
       "19880         [Fiction, Romance, Historical, Cultural]  \n",
       "23352                                     [Nonfiction]  \n",
       "16021  [Fiction, Mystery, Historical, Science Fiction]  \n",
       "49981                     [Thriller, Fiction, Mystery]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show training data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download training images\n",
    "#download_images(train,\"train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download test images\n",
    "#download_images(test, \"test_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename_col = return_image_name_col(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[['genres_cut']]\n",
    "train_df['file_name'] = train_filename_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>[Romance, Contemporary]</td>\n",
       "      <td>6377.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19880</th>\n",
       "      <td>[Fiction, Romance, Historical, Cultural]</td>\n",
       "      <td>19880.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>[Nonfiction]</td>\n",
       "      <td>23352.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>[Fiction, Mystery, Historical, Science Fiction]</td>\n",
       "      <td>16021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>[Thriller, Fiction, Mystery]</td>\n",
       "      <td>49981.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            genres_cut  file_name\n",
       "6377                           [Romance, Contemporary]   6377.jpg\n",
       "19880         [Fiction, Romance, Historical, Cultural]  19880.jpg\n",
       "23352                                     [Nonfiction]  23352.jpg\n",
       "16021  [Fiction, Mystery, Historical, Science Fiction]  16021.jpg\n",
       "49981                     [Thriller, Fiction, Mystery]  49981.jpg"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>[Romance, Fiction]</td>\n",
       "      <td>9102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34116</th>\n",
       "      <td>[History, Biography, Nonfiction]</td>\n",
       "      <td>34116.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53879</th>\n",
       "      <td>[Crime, Fiction, Mystery, Thriller]</td>\n",
       "      <td>53879.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30327</th>\n",
       "      <td>[Childrens, Fantasy]</td>\n",
       "      <td>30327.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36487</th>\n",
       "      <td>[Young Adult, Fantasy]</td>\n",
       "      <td>36487.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                genres_cut  file_name\n",
       "9102                    [Romance, Fiction]   9102.jpg\n",
       "34116     [History, Biography, Nonfiction]  34116.jpg\n",
       "53879  [Crime, Fiction, Mystery, Thriller]  53879.jpg\n",
       "30327                 [Childrens, Fantasy]  30327.jpg\n",
       "36487               [Young Adult, Fantasy]  36487.jpg"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filename_col = return_image_name_col(test)\n",
    "test_df = test[['genres_cut']]\n",
    "test_df['file_name'] = test_filename_col\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_valid = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in train_df.iterrows():\n",
    "    path = 'train_images/' + row['file_name']\n",
    "    if os.stat(path).st_size < 1024:\n",
    "        train_df_valid.drop(index = index,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36298, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_valid = test_df.copy()\n",
    "for index,row in test_df.iterrows():\n",
    "    path = 'test_images/' + row['file_name']\n",
    "    if os.stat(path).st_size < 1024:\n",
    "        test_df_valid.drop(index = index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12096, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_out = open(\"train_images_valid.pickle\",\"wb\")\n",
    "#pickle.dump(train_df_valid, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_out = open(\"test_images_valid.pickle\",\"wb\")\n",
    "#pickle.dump(test_df_valid, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = np.unique(list(itertools.chain.from_iterable(train_df['genres_cut'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulid the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(100,100,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(23, activation='sigmoid'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=[hn_multilabel_loss],metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(),\n",
    "            EarlyStopping(patience=4),\n",
    "            ModelCheckpoint(filepath='model.h5', save_best_only=True)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New train feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29038 validated image filenames belonging to 23 classes.\n",
      "Found 7260 validated image filenames.\n",
      "Epoch 1/15\n",
      "907/907 [==============================] - 486s 535ms/step - loss: 7.9275 - f1: 0.2054\n",
      "Epoch 2/15\n",
      "907/907 [==============================] - 518s 571ms/step - loss: 7.5442 - f1: 0.2265\n",
      "Epoch 3/15\n",
      "907/907 [==============================] - 562s 620ms/step - loss: 7.3847 - f1: 0.2448\n",
      "Epoch 4/15\n",
      "907/907 [==============================] - 577s 636ms/step - loss: 7.2603 - f1: 0.2626\n",
      "Epoch 5/15\n",
      "907/907 [==============================] - 559s 617ms/step - loss: 7.1624 - f1: 0.2751\n",
      "Epoch 6/15\n",
      "907/907 [==============================] - 548s 604ms/step - loss: 7.0668 - f1: 0.2883\n",
      "Epoch 7/15\n",
      "907/907 [==============================] - 458s 505ms/step - loss: 6.9818 - f1: 0.3001\n",
      "Epoch 8/15\n",
      "907/907 [==============================] - 455s 502ms/step - loss: 6.8991 - f1: 0.3098\n",
      "Epoch 9/15\n",
      "907/907 [==============================] - 455s 501ms/step - loss: 6.8139 - f1: 0.3240\n",
      "Epoch 10/15\n",
      "907/907 [==============================] - 456s 502ms/step - loss: 6.7348 - f1: 0.3324\n",
      "Epoch 11/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.6518 - f1: 0.3473\n",
      "Epoch 12/15\n",
      "907/907 [==============================] - 455s 502ms/step - loss: 6.5861 - f1: 0.3575\n",
      "Epoch 13/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.5000 - f1: 0.3688\n",
      "Epoch 14/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.4493 - f1: 0.3781\n",
      "Epoch 15/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.3800 - f1: 0.3902\n",
      "7260/7260 [==============================] - 83s 11ms/step\n",
      "Found 29038 validated image filenames belonging to 23 classes.\n",
      "Found 7260 validated image filenames.\n",
      "Epoch 1/15\n",
      "907/907 [==============================] - 455s 502ms/step - loss: 6.5468 - f1: 0.3733\n",
      "Epoch 2/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.5002 - f1: 0.3781\n",
      "Epoch 3/15\n",
      "907/907 [==============================] - 455s 502ms/step - loss: 6.4485 - f1: 0.3847\n",
      "Epoch 4/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.3863 - f1: 0.3940\n",
      "Epoch 5/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.3578 - f1: 0.3987\n",
      "Epoch 6/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.3180 - f1: 0.4059\n",
      "Epoch 7/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.2787 - f1: 0.4118\n",
      "Epoch 8/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.2390 - f1: 0.4156\n",
      "Epoch 9/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.2117 - f1: 0.4245\n",
      "Epoch 10/15\n",
      "907/907 [==============================] - 455s 501ms/step - loss: 6.1937 - f1: 0.4258\n",
      "Epoch 11/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.1784 - f1: 0.4273\n",
      "Epoch 12/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.1556 - f1: 0.4333\n",
      "Epoch 13/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.1105 - f1: 0.4350\n",
      "Epoch 14/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.0770 - f1: 0.4443\n",
      "Epoch 15/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.0580 - f1: 0.4494\n",
      "7260/7260 [==============================] - 85s 12ms/step\n",
      "Found 29038 validated image filenames belonging to 23 classes.\n",
      "Found 7260 validated image filenames.\n",
      "Epoch 1/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.3909 - f1: 0.4133\n",
      "Epoch 2/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.3707 - f1: 0.4151\n",
      "Epoch 3/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.3389 - f1: 0.4135\n",
      "Epoch 4/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.3002 - f1: 0.4222\n",
      "Epoch 5/15\n",
      "907/907 [==============================] - 455s 501ms/step - loss: 6.2726 - f1: 0.4256\n",
      "Epoch 6/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.2512 - f1: 0.4301\n",
      "Epoch 7/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.2492 - f1: 0.4262\n",
      "Epoch 8/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.2157 - f1: 0.4342\n",
      "Epoch 9/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.1875 - f1: 0.4366\n",
      "Epoch 10/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.1860 - f1: 0.4372\n",
      "Epoch 11/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.1595 - f1: 0.4415\n",
      "Epoch 12/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.1393 - f1: 0.4452\n",
      "Epoch 13/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.1318 - f1: 0.4473\n",
      "Epoch 14/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.0964 - f1: 0.4509\n",
      "Epoch 15/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.0782 - f1: 0.4568\n",
      "7260/7260 [==============================] - 83s 11ms/step\n",
      "Found 29039 validated image filenames belonging to 23 classes.\n",
      "Found 7259 validated image filenames.\n",
      "Epoch 1/15\n",
      "907/907 [==============================] - 454s 501ms/step - loss: 6.3126 - f1: 0.4325\n",
      "Epoch 2/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.3024 - f1: 0.4311\n",
      "Epoch 3/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.2405 - f1: 0.4390\n",
      "Epoch 4/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.2250 - f1: 0.4396\n",
      "Epoch 5/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.1990 - f1: 0.4429\n",
      "Epoch 6/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.1458 - f1: 0.4505\n",
      "Epoch 7/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.1474 - f1: 0.4502\n",
      "Epoch 8/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.1316 - f1: 0.4555\n",
      "Epoch 9/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.0939 - f1: 0.4582\n",
      "Epoch 10/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.0744 - f1: 0.4616\n",
      "Epoch 11/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 6.0834 - f1: 0.4609\n",
      "Epoch 12/15\n",
      "907/907 [==============================] - 455s 501ms/step - loss: 6.0361 - f1: 0.4685\n",
      "Epoch 13/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.0436 - f1: 0.4663\n",
      "Epoch 14/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.0322 - f1: 0.4681\n",
      "Epoch 15/15\n",
      "907/907 [==============================] - 455s 501ms/step - loss: 5.9906 - f1: 0.4736\n",
      "7259/7259 [==============================] - 83s 11ms/step\n",
      "Found 29039 validated image filenames belonging to 23 classes.\n",
      "Found 7259 validated image filenames.\n",
      "Epoch 1/15\n",
      "907/907 [==============================] - 455s 501ms/step - loss: 6.1968 - f1: 0.4503\n",
      "Epoch 2/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.1871 - f1: 0.4475\n",
      "Epoch 3/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.1679 - f1: 0.4500\n",
      "Epoch 4/15\n",
      "907/907 [==============================] - 456s 503ms/step - loss: 6.1554 - f1: 0.4526\n",
      "Epoch 5/15\n",
      "907/907 [==============================] - 455s 501ms/step - loss: 6.1069 - f1: 0.4574\n",
      "Epoch 6/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.0922 - f1: 0.4598\n",
      "Epoch 7/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.0738 - f1: 0.4621\n",
      "Epoch 8/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.0575 - f1: 0.4651\n",
      "Epoch 9/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 6.0518 - f1: 0.4640\n",
      "Epoch 10/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 6.0125 - f1: 0.4705\n",
      "Epoch 11/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 5.9885 - f1: 0.4720\n",
      "Epoch 12/15\n",
      "907/907 [==============================] - 456s 502ms/step - loss: 5.9668 - f1: 0.4768\n",
      "Epoch 13/15\n",
      "907/907 [==============================] - 454s 500ms/step - loss: 5.9648 - f1: 0.4758\n",
      "Epoch 14/15\n",
      "907/907 [==============================] - 453s 500ms/step - loss: 5.9339 - f1: 0.4789\n",
      "Epoch 15/15\n",
      "907/907 [==============================] - 453s 499ms/step - loss: 5.9326 - f1: 0.4816\n",
      "7259/7259 [==============================] - 83s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(train_df_valid):\n",
    "    #print(train_index,test_index)\n",
    "    #train generator\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_valid.iloc[train_index],\n",
    "    directory=\"train_images\",\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"genres_cut\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=list(all_classes),\n",
    "    target_size=(100,100))\n",
    "    \n",
    "    #test generator \n",
    "    test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_valid.iloc[test_index],\n",
    "    directory=\"train_images\",\n",
    "    x_col=\"file_name\",\n",
    "    y_col=None,\n",
    "    batch_size=1,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(100,100))\n",
    "    \n",
    "    #fitting the model\n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=15,\n",
    "                    callbacks=callbacks)\n",
    "    #prediction\n",
    "    test_generator.reset()\n",
    "    pred=model.predict_generator(test_generator,\n",
    "    steps=STEP_SIZE_TEST,\n",
    "    verbose=1)\n",
    "    \n",
    "    pred_bool = (pred > 0.5)\n",
    "    \n",
    "\n",
    "    predictions = []\n",
    "    labels = train_generator.class_indices\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    for row in pred_bool:\n",
    "        l=[]\n",
    "        for index,cls in enumerate(row):\n",
    "            if cls:\n",
    "                l.append(labels[index])\n",
    "        predictions.append(l)\n",
    "    predictions_lst.extend(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36298"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train = train_df_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['keras_pred'] = predictions_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "      <th>keras_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>[Romance, Contemporary]</td>\n",
       "      <td>6377.jpg</td>\n",
       "      <td>[Fantasy, Paranormal, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19880</th>\n",
       "      <td>[Fiction, Romance, Historical, Cultural]</td>\n",
       "      <td>19880.jpg</td>\n",
       "      <td>[Fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>[Nonfiction]</td>\n",
       "      <td>23352.jpg</td>\n",
       "      <td>[Fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>[Fiction, Mystery, Historical, Science Fiction]</td>\n",
       "      <td>16021.jpg</td>\n",
       "      <td>[Fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>[Thriller, Fiction, Mystery]</td>\n",
       "      <td>49981.jpg</td>\n",
       "      <td>[Fiction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            genres_cut  file_name  \\\n",
       "6377                           [Romance, Contemporary]   6377.jpg   \n",
       "19880         [Fiction, Romance, Historical, Cultural]  19880.jpg   \n",
       "23352                                     [Nonfiction]  23352.jpg   \n",
       "16021  [Fiction, Mystery, Historical, Science Fiction]  16021.jpg   \n",
       "49981                     [Thriller, Fiction, Mystery]  49981.jpg   \n",
       "\n",
       "                           keras_pred  \n",
       "6377   [Fantasy, Paranormal, Romance]  \n",
       "19880                       [Fiction]  \n",
       "23352                       [Fiction]  \n",
       "16021                       [Fiction]  \n",
       "49981                       [Fiction]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"train_with_new_feature.pickle\",\"wb\")\n",
    "pickle.dump(new_feature_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New test feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36298 validated image filenames belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train_df_valid,\n",
    "directory=\"train_images\",\n",
    "x_col=\"file_name\",\n",
    "y_col=\"genres_cut\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "classes=list(all_classes),\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12096 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_df_valid,\n",
    "directory=\"test_images\",\n",
    "x_col=\"file_name\",\n",
    "y_col=None,\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulid the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(100,100,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(23, activation='sigmoid'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=[hn_multilabel_loss],metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(),\n",
    "            EarlyStopping(patience=4),\n",
    "            ModelCheckpoint(filepath='model-simple2.h5', save_best_only=True)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1134/1134 [==============================] - 673s 594ms/step - loss: 7.8354 - f1: 0.2092\n",
      "Epoch 2/15\n",
      "1134/1134 [==============================] - 694s 612ms/step - loss: 7.4744 - f1: 0.2400\n",
      "Epoch 3/15\n",
      "1134/1134 [==============================] - 667s 588ms/step - loss: 7.3093 - f1: 0.2628\n",
      "Epoch 4/15\n",
      "1134/1134 [==============================] - 724s 638ms/step - loss: 7.1994 - f1: 0.2758\n",
      "Epoch 5/15\n",
      "1134/1134 [==============================] - 665s 586ms/step - loss: 7.0796 - f1: 0.2939\n",
      "Epoch 6/15\n",
      "1134/1134 [==============================] - 668s 589ms/step - loss: 6.9800 - f1: 0.3045\n",
      "Epoch 7/15\n",
      "1134/1134 [==============================] - 610s 537ms/step - loss: 6.8964 - f1: 0.3140\n",
      "Epoch 8/15\n",
      "1134/1134 [==============================] - 569s 502ms/step - loss: 6.8196 - f1: 0.3253\n",
      "Epoch 9/15\n",
      "1134/1134 [==============================] - 568s 501ms/step - loss: 6.7528 - f1: 0.3338\n",
      "Epoch 10/15\n",
      "1134/1134 [==============================] - 568s 501ms/step - loss: 6.6860 - f1: 0.3451\n",
      "Epoch 11/15\n",
      "1134/1134 [==============================] - 567s 500ms/step - loss: 6.6358 - f1: 0.3509\n",
      "Epoch 12/15\n",
      "1134/1134 [==============================] - 569s 501ms/step - loss: 6.5772 - f1: 0.3622\n",
      "Epoch 13/15\n",
      "1134/1134 [==============================] - 568s 501ms/step - loss: 6.5459 - f1: 0.3699\n",
      "Epoch 14/15\n",
      "1134/1134 [==============================] - 568s 501ms/step - loss: 6.5032 - f1: 0.3765\n",
      "Epoch 15/15\n",
      "1134/1134 [==============================] - 569s 502ms/step - loss: 6.4663 - f1: 0.3841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb3f0b9c630>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=15,\n",
    "                    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12096/12096 [==============================] - 184s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.1069563e-04, 3.5543285e-02, 5.2862433e-03, 1.9549245e-02,\n",
       "       3.4089231e-01, 1.2600668e-03, 3.9944261e-02, 7.8190360e-03,\n",
       "       1.0479687e-02, 2.2908087e-01, 1.7063333e-01, 2.6924433e-02,\n",
       "       2.2126318e-04, 3.2485332e-02, 1.0209440e-02, 1.7553844e-02,\n",
       "       4.1463187e-01, 1.2642478e-02, 1.8559820e-03, 5.3337640e-01,\n",
       "       3.6512255e-03, 2.1477186e-03, 1.9528612e-02], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = (pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions=[]\n",
    "predictions2 = []\n",
    "labels = train_generator.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(labels[index])\n",
    "    predictions2.append(l)\n",
    "#    predictions.append(\",\".join(l))\n",
    "#filenames=test_generator.filenames\n",
    "#results=pd.DataFrame({\"Filename\":filenames,\n",
    "#                      \"Predictions\":predictions})\n",
    "#results.to_csv(\"results_keras.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_test = test_df_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "      <th>keras_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>[Romance, Fiction]</td>\n",
       "      <td>9102.jpg</td>\n",
       "      <td>[Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34116</th>\n",
       "      <td>[History, Biography, Nonfiction]</td>\n",
       "      <td>34116.jpg</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53879</th>\n",
       "      <td>[Crime, Fiction, Mystery, Thriller]</td>\n",
       "      <td>53879.jpg</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30327</th>\n",
       "      <td>[Childrens, Fantasy]</td>\n",
       "      <td>30327.jpg</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36487</th>\n",
       "      <td>[Young Adult, Fantasy]</td>\n",
       "      <td>36487.jpg</td>\n",
       "      <td>[Fiction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                genres_cut  file_name keras_pred\n",
       "9102                    [Romance, Fiction]   9102.jpg  [Romance]\n",
       "34116     [History, Biography, Nonfiction]  34116.jpg         []\n",
       "53879  [Crime, Fiction, Mystery, Thriller]  53879.jpg         []\n",
       "30327                 [Childrens, Fantasy]  30327.jpg         []\n",
       "36487               [Young Adult, Fantasy]  36487.jpg  [Fiction]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_test['keras_pred'] = predictions2\n",
    "new_feature_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"test_with_new_feature.pickle\",\"wb\")\n",
    "pickle.dump(new_feature_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
