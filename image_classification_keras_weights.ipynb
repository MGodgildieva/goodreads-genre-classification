{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import urllib.request as req\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hamming loss\n",
    "def hn_multilabel_loss(y_true, y_pred):\n",
    "    # Avoid divide by 0\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Multi-task loss\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_image_name_col(df):\n",
    "    ids = df.index.values\n",
    "    names = []\n",
    "    for i in ids:\n",
    "        names.append(str(i)+'.jpg')\n",
    "    return np.array(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training set\n",
    "pickle_in_train = open(\"all_books_train.pickle\",\"rb\")\n",
    "train = pickle.load(pickle_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test set\n",
    "pickle_in_test = open(\"all_books_test.pickle\",\"rb\")\n",
    "test = pickle.load(pickle_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36389, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12131, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename_col = return_image_name_col(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[['genres_cut']]\n",
    "train_df['file_name'] = train_filename_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>[Romance, Contemporary]</td>\n",
       "      <td>6377.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19880</th>\n",
       "      <td>[Fiction, Romance, Historical, Cultural]</td>\n",
       "      <td>19880.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>[Nonfiction]</td>\n",
       "      <td>23352.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>[Fiction, Mystery, Historical, Science Fiction]</td>\n",
       "      <td>16021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>[Thriller, Fiction, Mystery]</td>\n",
       "      <td>49981.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            genres_cut  file_name\n",
       "6377                           [Romance, Contemporary]   6377.jpg\n",
       "19880         [Fiction, Romance, Historical, Cultural]  19880.jpg\n",
       "23352                                     [Nonfiction]  23352.jpg\n",
       "16021  [Fiction, Mystery, Historical, Science Fiction]  16021.jpg\n",
       "49981                     [Thriller, Fiction, Mystery]  49981.jpg"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>[Romance, Fiction]</td>\n",
       "      <td>9102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34116</th>\n",
       "      <td>[History, Biography, Nonfiction]</td>\n",
       "      <td>34116.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53879</th>\n",
       "      <td>[Crime, Fiction, Mystery, Thriller]</td>\n",
       "      <td>53879.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30327</th>\n",
       "      <td>[Childrens, Fantasy]</td>\n",
       "      <td>30327.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36487</th>\n",
       "      <td>[Young Adult, Fantasy]</td>\n",
       "      <td>36487.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                genres_cut  file_name\n",
       "9102                    [Romance, Fiction]   9102.jpg\n",
       "34116     [History, Biography, Nonfiction]  34116.jpg\n",
       "53879  [Crime, Fiction, Mystery, Thriller]  53879.jpg\n",
       "30327                 [Childrens, Fantasy]  30327.jpg\n",
       "36487               [Young Adult, Fantasy]  36487.jpg"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filename_col = return_image_name_col(test)\n",
    "test_df = test[['genres_cut']]\n",
    "test_df['file_name'] = test_filename_col\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_valid = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in train_df.iterrows():\n",
    "    path = 'train_images/' + row['file_name']\n",
    "    if os.stat(path).st_size < 1024:\n",
    "        train_df_valid.drop(index = index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36298, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_valid = test_df.copy()\n",
    "for index,row in test_df.iterrows():\n",
    "    path = 'test_images/' + row['file_name']\n",
    "    if os.stat(path).st_size < 1024:\n",
    "        test_df_valid.drop(index = index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12096, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = np.unique(list(itertools.chain.from_iterable(train_df['genres_cut'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_count = []\n",
    "for cl in all_classes:\n",
    "    c = sum(l.count(cl) for l in list(train_df_valid['genres_cut']))\n",
    "    genres_count.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_genres = pd.DataFrame({'genre':all_classes, 'count':genres_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_genres['class_weight'] = len(train_df_valid['genres_cut'])/most_common_genres['count']\n",
    "class_weights = {}\n",
    "for i, row in most_common_genres.iterrows():\n",
    "    class_weights[i] = row['class_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 21.839951865222623,\n",
       " 1: 20.741714285714284,\n",
       " 2: 12.691608391608392,\n",
       " 3: 7.965328066710555,\n",
       " 4: 8.068015114469882,\n",
       " 5: 23.646905537459283,\n",
       " 6: 10.091187100361413,\n",
       " 7: 16.85926614026939,\n",
       " 8: 3.424662704028682,\n",
       " 9: 1.895852919669905,\n",
       " 10: 6.9007604562737646,\n",
       " 11: 18.472264631043256,\n",
       " 12: 21.214494447691408,\n",
       " 13: 22.872085696282294,\n",
       " 14: 13.408939785740673,\n",
       " 15: 8.599384032219852,\n",
       " 16: 6.41647516351423,\n",
       " 17: 20.06522940851299,\n",
       " 18: 9.408501814411613,\n",
       " 19: 3.7905179615705933,\n",
       " 20: 9.577308707124011,\n",
       " 21: 16.061061946902655,\n",
       " 22: 4.622182605373743}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulid the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(100,100,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(23, activation='sigmoid'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=[hn_multilabel_loss],metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(),\n",
    "            EarlyStopping(patience=4),\n",
    "            ModelCheckpoint(filepath='model.h5', save_best_only=True)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29038 validated image filenames belonging to 23 classes.\n",
      "Found 7260 validated image filenames.\n",
      "Epoch 1/30\n",
      "907/907 [==============================] - 903s 996ms/step - loss: 69.6767 - f1: 0.1987\n",
      "Epoch 2/30\n",
      "907/907 [==============================] - 889s 980ms/step - loss: 66.6156 - f1: 0.2229\n",
      "Epoch 3/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 65.2165 - f1: 0.2442\n",
      "Epoch 4/30\n",
      "907/907 [==============================] - 891s 983ms/step - loss: 64.1352 - f1: 0.2633\n",
      "Epoch 5/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 63.2054 - f1: 0.2779\n",
      "Epoch 6/30\n",
      "907/907 [==============================] - 889s 980ms/step - loss: 62.3909 - f1: 0.2880\n",
      "Epoch 7/30\n",
      "907/907 [==============================] - 889s 980ms/step - loss: 61.5744 - f1: 0.3019\n",
      "Epoch 8/30\n",
      "907/907 [==============================] - 887s 977ms/step - loss: 60.8151 - f1: 0.3096\n",
      "Epoch 9/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 60.0462 - f1: 0.3226\n",
      "Epoch 10/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 59.1663 - f1: 0.3330\n",
      "Epoch 11/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 58.5876 - f1: 0.3455\n",
      "Epoch 12/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 57.9569 - f1: 0.3561\n",
      "Epoch 13/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 57.1177 - f1: 0.3674\n",
      "Epoch 14/30\n",
      "907/907 [==============================] - 889s 980ms/step - loss: 56.6838 - f1: 0.3771\n",
      "Epoch 15/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 56.0798 - f1: 0.3882\n",
      "Epoch 16/30\n",
      "907/907 [==============================] - 889s 980ms/step - loss: 55.6442 - f1: 0.3976\n",
      "Epoch 17/30\n",
      "907/907 [==============================] - 888s 979ms/step - loss: 55.1420 - f1: 0.4050\n",
      "Epoch 18/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 54.7974 - f1: 0.4126\n",
      "Epoch 19/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 54.3922 - f1: 0.4191\n",
      "Epoch 20/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 54.1312 - f1: 0.4231\n",
      "Epoch 21/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 53.5371 - f1: 0.4361\n",
      "Epoch 22/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 53.4539 - f1: 0.4398\n",
      "Epoch 23/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 53.0528 - f1: 0.4448\n",
      "Epoch 24/30\n",
      "907/907 [==============================] - 884s 975ms/step - loss: 52.9280 - f1: 0.4482\n",
      "Epoch 25/30\n",
      "907/907 [==============================] - 888s 979ms/step - loss: 52.5895 - f1: 0.4547\n",
      "Epoch 26/30\n",
      "907/907 [==============================] - 888s 979ms/step - loss: 52.6720 - f1: 0.4565\n",
      "Epoch 27/30\n",
      "907/907 [==============================] - 888s 979ms/step - loss: 52.3010 - f1: 0.4610\n",
      "Epoch 28/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 52.3010 - f1: 0.4665\n",
      "Epoch 29/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 52.1492 - f1: 0.4670\n",
      "Epoch 30/30\n",
      "907/907 [==============================] - 860s 948ms/step - loss: 52.0579 - f1: 0.4700\n",
      "7260/7260 [==============================] - 198s 27ms/step\n",
      "Found 29038 validated image filenames belonging to 23 classes.\n",
      "Found 7260 validated image filenames.\n",
      "Epoch 1/30\n",
      "907/907 [==============================] - 888s 979ms/step - loss: 56.2981 - f1: 0.4146\n",
      "Epoch 2/30\n",
      "907/907 [==============================] - 886s 976ms/step - loss: 55.9989 - f1: 0.4116\n",
      "Epoch 3/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 55.8240 - f1: 0.4118\n",
      "Epoch 4/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 55.6519 - f1: 0.4182\n",
      "Epoch 5/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 55.2580 - f1: 0.4216\n",
      "Epoch 6/30\n",
      "907/907 [==============================] - 883s 974ms/step - loss: 54.9585 - f1: 0.4273\n",
      "Epoch 7/30\n",
      "907/907 [==============================] - 933s 1s/step - loss: 54.9179 - f1: 0.4287\n",
      "Epoch 8/30\n",
      "907/907 [==============================] - 1069s 1s/step - loss: 54.5399 - f1: 0.4343\n",
      "Epoch 9/30\n",
      "907/907 [==============================] - 608s 671ms/step - loss: 54.2967 - f1: 0.4418\n",
      "Epoch 10/30\n",
      "907/907 [==============================] - 586s 647ms/step - loss: 54.0091 - f1: 0.4423\n",
      "Epoch 11/30\n",
      "907/907 [==============================] - 553s 610ms/step - loss: 53.9307 - f1: 0.4460\n",
      "Epoch 12/30\n",
      "907/907 [==============================] - 567s 625ms/step - loss: 53.7928 - f1: 0.4487\n",
      "Epoch 13/30\n",
      "907/907 [==============================] - 548s 604ms/step - loss: 53.3264 - f1: 0.4547\n",
      "Epoch 14/30\n",
      "907/907 [==============================] - 547s 603ms/step - loss: 53.3203 - f1: 0.4557\n",
      "Epoch 15/30\n",
      "907/907 [==============================] - 553s 609ms/step - loss: 52.9304 - f1: 0.4610\n",
      "Epoch 16/30\n",
      "907/907 [==============================] - 586s 647ms/step - loss: 52.9225 - f1: 0.4653\n",
      "Epoch 17/30\n",
      "907/907 [==============================] - 582s 642ms/step - loss: 52.7429 - f1: 0.4652\n",
      "Epoch 18/30\n",
      "907/907 [==============================] - 581s 640ms/step - loss: 52.5480 - f1: 0.4714\n",
      "Epoch 19/30\n",
      "907/907 [==============================] - 561s 618ms/step - loss: 52.4430 - f1: 0.4716\n",
      "Epoch 20/30\n",
      "907/907 [==============================] - 562s 620ms/step - loss: 52.2022 - f1: 0.4786\n",
      "Epoch 21/30\n",
      "907/907 [==============================] - 577s 636ms/step - loss: 51.8143 - f1: 0.4832\n",
      "Epoch 22/30\n",
      "907/907 [==============================] - 569s 628ms/step - loss: 52.0825 - f1: 0.4818\n",
      "Epoch 23/30\n",
      "907/907 [==============================] - 582s 642ms/step - loss: 51.8328 - f1: 0.4850\n",
      "Epoch 24/30\n",
      "907/907 [==============================] - 541s 597ms/step - loss: 51.6520 - f1: 0.4846\n",
      "Epoch 25/30\n",
      "907/907 [==============================] - 521s 574ms/step - loss: 51.3498 - f1: 0.4889\n",
      "Epoch 26/30\n",
      "907/907 [==============================] - 533s 587ms/step - loss: 51.5306 - f1: 0.4906\n",
      "Epoch 27/30\n",
      "907/907 [==============================] - 499s 550ms/step - loss: 51.5701 - f1: 0.4913\n",
      "Epoch 28/30\n",
      "907/907 [==============================] - 492s 542ms/step - loss: 51.1757 - f1: 0.4945\n",
      "Epoch 29/30\n",
      "907/907 [==============================] - 521s 574ms/step - loss: 50.9505 - f1: 0.4978\n",
      "Epoch 30/30\n",
      "907/907 [==============================] - 495s 546ms/step - loss: 51.0221 - f1: 0.4974\n",
      "7260/7260 [==============================] - 90s 12ms/step\n",
      "Found 29038 validated image filenames belonging to 23 classes.\n",
      "Found 7260 validated image filenames.\n",
      "Epoch 1/30\n",
      "907/907 [==============================] - 509s 561ms/step - loss: 55.2758 - f1: 0.4461\n",
      "Epoch 2/30\n",
      "907/907 [==============================] - 496s 547ms/step - loss: 55.2834 - f1: 0.4447\n",
      "Epoch 3/30\n",
      "907/907 [==============================] - 505s 557ms/step - loss: 54.8951 - f1: 0.4472\n",
      "Epoch 4/30\n",
      "907/907 [==============================] - 494s 545ms/step - loss: 54.6134 - f1: 0.4510\n",
      "Epoch 5/30\n",
      "907/907 [==============================] - 489s 539ms/step - loss: 54.2803 - f1: 0.4525\n",
      "Epoch 6/30\n",
      "907/907 [==============================] - 474s 523ms/step - loss: 53.9767 - f1: 0.4593\n",
      "Epoch 7/30\n",
      "907/907 [==============================] - 476s 525ms/step - loss: 54.0340 - f1: 0.4593\n",
      "Epoch 8/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 53.5405 - f1: 0.4635\n",
      "Epoch 9/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 53.3158 - f1: 0.4679\n",
      "Epoch 10/30\n",
      "907/907 [==============================] - 466s 514ms/step - loss: 53.5543 - f1: 0.4646\n",
      "Epoch 11/30\n",
      "907/907 [==============================] - 468s 516ms/step - loss: 53.2752 - f1: 0.4675\n",
      "Epoch 12/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.9734 - f1: 0.4734\n",
      "Epoch 13/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.4597 - f1: 0.4781\n",
      "Epoch 14/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.5741 - f1: 0.4803\n",
      "Epoch 15/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.5567 - f1: 0.4802\n",
      "Epoch 16/30\n",
      "907/907 [==============================] - 468s 516ms/step - loss: 52.4455 - f1: 0.4828\n",
      "Epoch 17/30\n",
      "907/907 [==============================] - 468s 516ms/step - loss: 52.2990 - f1: 0.4807\n",
      "Epoch 18/30\n",
      "907/907 [==============================] - 469s 517ms/step - loss: 52.1023 - f1: 0.4886\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907/907 [==============================] - 469s 517ms/step - loss: 51.7878 - f1: 0.4895\n",
      "Epoch 20/30\n",
      "907/907 [==============================] - 487s 537ms/step - loss: 51.8012 - f1: 0.4905\n",
      "Epoch 21/30\n",
      "907/907 [==============================] - 507s 559ms/step - loss: 51.7571 - f1: 0.4926\n",
      "Epoch 22/30\n",
      "907/907 [==============================] - 504s 555ms/step - loss: 51.4925 - f1: 0.4965\n",
      "Epoch 23/30\n",
      "907/907 [==============================] - 499s 550ms/step - loss: 51.3246 - f1: 0.4960\n",
      "Epoch 24/30\n",
      "907/907 [==============================] - 562s 619ms/step - loss: 51.3598 - f1: 0.4964\n",
      "Epoch 25/30\n",
      "907/907 [==============================] - 600s 662ms/step - loss: 51.4710 - f1: 0.4959\n",
      "Epoch 26/30\n",
      "907/907 [==============================] - 557s 614ms/step - loss: 51.3844 - f1: 0.4963\n",
      "Epoch 27/30\n",
      "907/907 [==============================] - 588s 648ms/step - loss: 51.3936 - f1: 0.4980\n",
      "Epoch 28/30\n",
      "907/907 [==============================] - 570s 628ms/step - loss: 51.0885 - f1: 0.4984\n",
      "Epoch 29/30\n",
      "907/907 [==============================] - 509s 562ms/step - loss: 51.3628 - f1: 0.4979\n",
      "Epoch 30/30\n",
      "907/907 [==============================] - 580s 639ms/step - loss: 51.0480 - f1: 0.5012\n",
      "7260/7260 [==============================] - 100s 14ms/step\n",
      "Found 29039 validated image filenames belonging to 23 classes.\n",
      "Found 7259 validated image filenames.\n",
      "Epoch 1/30\n",
      "907/907 [==============================] - 577s 637ms/step - loss: 53.8857 - f1: 0.4619\n",
      "Epoch 2/30\n",
      "907/907 [==============================] - 573s 632ms/step - loss: 53.7465 - f1: 0.4618\n",
      "Epoch 3/30\n",
      "907/907 [==============================] - 600s 661ms/step - loss: 53.5081 - f1: 0.4677\n",
      "Epoch 4/30\n",
      "907/907 [==============================] - 557s 614ms/step - loss: 53.5691 - f1: 0.4635\n",
      "Epoch 5/30\n",
      "907/907 [==============================] - 583s 643ms/step - loss: 53.4206 - f1: 0.4679\n",
      "Epoch 6/30\n",
      "907/907 [==============================] - 596s 657ms/step - loss: 53.0817 - f1: 0.4693\n",
      "Epoch 7/30\n",
      "907/907 [==============================] - 561s 618ms/step - loss: 53.2328 - f1: 0.4683\n",
      "Epoch 8/30\n",
      "907/907 [==============================] - 498s 549ms/step - loss: 53.0243 - f1: 0.4708\n",
      "Epoch 9/30\n",
      "907/907 [==============================] - 562s 619ms/step - loss: 52.6604 - f1: 0.4729\n",
      "Epoch 10/30\n",
      "907/907 [==============================] - 618s 682ms/step - loss: 52.7208 - f1: 0.4746\n",
      "Epoch 11/30\n",
      "907/907 [==============================] - 576s 635ms/step - loss: 52.6440 - f1: 0.4766\n",
      "Epoch 12/30\n",
      "907/907 [==============================] - 568s 626ms/step - loss: 52.5435 - f1: 0.4761\n",
      "Epoch 13/30\n",
      "907/907 [==============================] - 518s 571ms/step - loss: 52.7278 - f1: 0.4739\n",
      "Epoch 14/30\n",
      "907/907 [==============================] - 540s 595ms/step - loss: 52.3330 - f1: 0.4796\n",
      "Epoch 15/30\n",
      "907/907 [==============================] - 559s 616ms/step - loss: 52.3030 - f1: 0.4793\n",
      "Epoch 16/30\n",
      "907/907 [==============================] - 534s 589ms/step - loss: 52.2536 - f1: 0.4821\n",
      "Epoch 17/30\n",
      "907/907 [==============================] - 575s 634ms/step - loss: 51.9232 - f1: 0.4854\n",
      "Epoch 18/30\n",
      "907/907 [==============================] - 537s 592ms/step - loss: 52.0457 - f1: 0.4848\n",
      "Epoch 19/30\n",
      "907/907 [==============================] - 514s 566ms/step - loss: 51.8063 - f1: 0.4858\n",
      "Epoch 20/30\n",
      "907/907 [==============================] - 539s 594ms/step - loss: 51.9364 - f1: 0.4877\n",
      "Epoch 21/30\n",
      "907/907 [==============================] - 554s 611ms/step - loss: 51.5588 - f1: 0.4889\n",
      "Epoch 22/30\n",
      "907/907 [==============================] - 539s 595ms/step - loss: 51.5525 - f1: 0.4903\n",
      "Epoch 23/30\n",
      "907/907 [==============================] - 530s 585ms/step - loss: 51.6295 - f1: 0.4875\n",
      "Epoch 24/30\n",
      "907/907 [==============================] - 535s 590ms/step - loss: 51.6606 - f1: 0.4917\n",
      "Epoch 25/30\n",
      "907/907 [==============================] - 606s 668ms/step - loss: 51.5141 - f1: 0.4901\n",
      "Epoch 26/30\n",
      "907/907 [==============================] - 561s 619ms/step - loss: 51.4603 - f1: 0.4927\n",
      "Epoch 27/30\n",
      "907/907 [==============================] - 585s 645ms/step - loss: 51.4101 - f1: 0.4923\n",
      "Epoch 28/30\n",
      "907/907 [==============================] - 647s 714ms/step - loss: 51.3291 - f1: 0.4932\n",
      "Epoch 29/30\n",
      "907/907 [==============================] - 650s 717ms/step - loss: 51.2599 - f1: 0.4945\n",
      "Epoch 30/30\n",
      "907/907 [==============================] - 598s 659ms/step - loss: 51.0508 - f1: 0.4942\n",
      "7259/7259 [==============================] - 106s 15ms/step\n",
      "Found 29039 validated image filenames belonging to 23 classes.\n",
      "Found 7259 validated image filenames.\n",
      "Epoch 1/30\n",
      "907/907 [==============================] - 552s 609ms/step - loss: 53.7775 - f1: 0.4628\n",
      "Epoch 2/30\n",
      "907/907 [==============================] - 555s 612ms/step - loss: 53.8558 - f1: 0.4617\n",
      "Epoch 3/30\n",
      "907/907 [==============================] - 580s 639ms/step - loss: 53.6557 - f1: 0.4662\n",
      "Epoch 4/30\n",
      "907/907 [==============================] - 593s 654ms/step - loss: 53.4414 - f1: 0.4667\n",
      "Epoch 5/30\n",
      "907/907 [==============================] - 729s 804ms/step - loss: 53.2084 - f1: 0.4677\n",
      "Epoch 6/30\n",
      "907/907 [==============================] - 690s 760ms/step - loss: 53.1088 - f1: 0.4685\n",
      "Epoch 7/30\n",
      "907/907 [==============================] - 575s 634ms/step - loss: 53.3976 - f1: 0.4701\n",
      "Epoch 8/30\n",
      "907/907 [==============================] - 502s 554ms/step - loss: 53.2497 - f1: 0.4685\n",
      "Epoch 9/30\n",
      "907/907 [==============================] - 472s 520ms/step - loss: 53.0831 - f1: 0.4681\n",
      "Epoch 10/30\n",
      "907/907 [==============================] - 465s 513ms/step - loss: 53.0101 - f1: 0.4713\n",
      "Epoch 11/30\n",
      "907/907 [==============================] - 466s 513ms/step - loss: 52.5928 - f1: 0.4771\n",
      "Epoch 12/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.7092 - f1: 0.4763\n",
      "Epoch 13/30\n",
      "907/907 [==============================] - 465s 513ms/step - loss: 52.8288 - f1: 0.4735\n",
      "Epoch 14/30\n",
      "907/907 [==============================] - 465s 513ms/step - loss: 52.6184 - f1: 0.4748\n",
      "Epoch 15/30\n",
      "907/907 [==============================] - 466s 514ms/step - loss: 52.4961 - f1: 0.4798\n",
      "Epoch 16/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.4211 - f1: 0.4768\n",
      "Epoch 17/30\n",
      "907/907 [==============================] - 468s 516ms/step - loss: 52.7114 - f1: 0.4741\n",
      "Epoch 18/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.3979 - f1: 0.4770\n",
      "Epoch 19/30\n",
      "907/907 [==============================] - 466s 514ms/step - loss: 52.4612 - f1: 0.4791\n",
      "Epoch 20/30\n",
      "907/907 [==============================] - 466s 513ms/step - loss: 52.0036 - f1: 0.4831\n",
      "Epoch 21/30\n",
      "907/907 [==============================] - 466s 514ms/step - loss: 52.3332 - f1: 0.4793\n",
      "Epoch 22/30\n",
      "907/907 [==============================] - 466s 514ms/step - loss: 51.9792 - f1: 0.4825\n",
      "Epoch 23/30\n",
      "907/907 [==============================] - 466s 514ms/step - loss: 51.9337 - f1: 0.4839\n",
      "Epoch 24/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.0194 - f1: 0.4818\n",
      "Epoch 25/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.0293 - f1: 0.4832\n",
      "Epoch 26/30\n",
      "907/907 [==============================] - 468s 516ms/step - loss: 51.8199 - f1: 0.4853\n",
      "Epoch 27/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 52.0948 - f1: 0.4829\n",
      "Epoch 28/30\n",
      "907/907 [==============================] - 466s 514ms/step - loss: 51.9628 - f1: 0.4811\n",
      "Epoch 29/30\n",
      "907/907 [==============================] - 467s 515ms/step - loss: 51.8691 - f1: 0.4835\n",
      "Epoch 30/30\n",
      "907/907 [==============================] - 467s 514ms/step - loss: 51.6465 - f1: 0.4867\n",
      "7259/7259 [==============================] - 84s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(train_df_valid):\n",
    "    #print(train_index,test_index)\n",
    "    #train generator\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_valid.iloc[train_index],\n",
    "    directory=\"train_images\",\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"genres_cut\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=list(all_classes),\n",
    "    target_size=(100,100))\n",
    "    \n",
    "    #test generator \n",
    "    test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_valid.iloc[test_index],\n",
    "    directory=\"train_images\",\n",
    "    x_col=\"file_name\",\n",
    "    y_col=None,\n",
    "    batch_size=1,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(100,100))\n",
    "    \n",
    "    #fitting the model\n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=30,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "    #prediction\n",
    "    test_generator.reset()\n",
    "    pred=model.predict_generator(test_generator,\n",
    "    steps=STEP_SIZE_TEST,\n",
    "    verbose=1)\n",
    "    \n",
    "    pred_bool = (pred > 0.5)\n",
    "    \n",
    "\n",
    "    predictions = []\n",
    "    labels = train_generator.class_indices\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    for row in pred_bool:\n",
    "        l=[]\n",
    "        for index,cls in enumerate(row):\n",
    "            if cls:\n",
    "                l.append(labels[index])\n",
    "        predictions.append(l)\n",
    "    predictions_lst.extend(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train = train_df_valid.copy()\n",
    "new_feature_train['keras_pred'] = predictions_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_out = open(\"train_with_weights.pickle\",\"wb\")\n",
    "pickle.dump(new_feature_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36298 validated image filenames belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train_df_valid,\n",
    "directory=\"train_images\",\n",
    "x_col=\"file_name\",\n",
    "y_col=\"genres_cut\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "classes=list(all_classes),\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12096 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_df_valid,\n",
    "directory=\"test_images\",\n",
    "x_col=\"file_name\",\n",
    "y_col=None,\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1134/1134 [==============================] - 648s 571ms/step - loss: 52.2010 - f1: 0.4740\n",
      "Epoch 2/30\n",
      "1134/1134 [==============================] - 640s 564ms/step - loss: 52.2060 - f1: 0.4735\n",
      "Epoch 3/30\n",
      "1134/1134 [==============================] - 719s 634ms/step - loss: 52.4316 - f1: 0.4708\n",
      "Epoch 4/30\n",
      "1134/1134 [==============================] - 665s 586ms/step - loss: 52.3420 - f1: 0.4734\n",
      "Epoch 5/30\n",
      "1134/1134 [==============================] - 697s 615ms/step - loss: 52.2235 - f1: 0.4714\n",
      "Epoch 6/30\n",
      "1134/1134 [==============================] - 603s 532ms/step - loss: 52.3170 - f1: 0.4729\n",
      "Epoch 7/30\n",
      "1134/1134 [==============================] - 625s 551ms/step - loss: 52.4972 - f1: 0.4691\n",
      "Epoch 8/30\n",
      "1134/1134 [==============================] - 642s 567ms/step - loss: 52.6011 - f1: 0.4689\n",
      "Epoch 9/30\n",
      "1134/1134 [==============================] - 643s 567ms/step - loss: 52.4156 - f1: 0.4701\n",
      "Epoch 10/30\n",
      "1134/1134 [==============================] - 643s 567ms/step - loss: 52.2780 - f1: 0.4728\n",
      "Epoch 11/30\n",
      "1134/1134 [==============================] - 613s 540ms/step - loss: 52.4897 - f1: 0.4699\n",
      "Epoch 12/30\n",
      "1134/1134 [==============================] - 632s 557ms/step - loss: 52.3436 - f1: 0.4716\n",
      "Epoch 13/30\n",
      "1134/1134 [==============================] - 638s 563ms/step - loss: 52.2163 - f1: 0.4720\n",
      "Epoch 14/30\n",
      "1134/1134 [==============================] - 598s 528ms/step - loss: 52.5352 - f1: 0.4699\n",
      "Epoch 15/30\n",
      "1134/1134 [==============================] - 598s 527ms/step - loss: 52.6254 - f1: 0.4689\n",
      "Epoch 16/30\n",
      "1134/1134 [==============================] - 613s 540ms/step - loss: 52.2396 - f1: 0.4720\n",
      "Epoch 17/30\n",
      "1134/1134 [==============================] - 611s 539ms/step - loss: 52.4481 - f1: 0.4730\n",
      "Epoch 18/30\n",
      "1134/1134 [==============================] - 753s 664ms/step - loss: 52.6079 - f1: 0.4671\n",
      "Epoch 19/30\n",
      "1134/1134 [==============================] - 725s 639ms/step - loss: 52.5950 - f1: 0.4654\n",
      "Epoch 20/30\n",
      "1134/1134 [==============================] - 740s 653ms/step - loss: 52.5018 - f1: 0.4749\n",
      "Epoch 21/30\n",
      "1134/1134 [==============================] - 671s 591ms/step - loss: 52.2798 - f1: 0.4725\n",
      "Epoch 22/30\n",
      "1134/1134 [==============================] - 739s 652ms/step - loss: 52.3446 - f1: 0.4716\n",
      "Epoch 23/30\n",
      "1134/1134 [==============================] - 614s 541ms/step - loss: 52.4797 - f1: 0.4717\n",
      "Epoch 24/30\n",
      "1134/1134 [==============================] - 635s 560ms/step - loss: 52.5679 - f1: 0.4669\n",
      "Epoch 25/30\n",
      "1134/1134 [==============================] - 607s 536ms/step - loss: 52.5040 - f1: 0.4699\n",
      "Epoch 26/30\n",
      "1134/1134 [==============================] - 594s 524ms/step - loss: 52.2755 - f1: 0.4708\n",
      "Epoch 27/30\n",
      "1134/1134 [==============================] - 588s 519ms/step - loss: 52.4076 - f1: 0.4721\n",
      "Epoch 28/30\n",
      "1134/1134 [==============================] - 589s 519ms/step - loss: 52.6662 - f1: 0.4680\n",
      "Epoch 29/30\n",
      "1134/1134 [==============================] - 623s 550ms/step - loss: 52.3771 - f1: 0.4700\n",
      "Epoch 30/30\n",
      "1134/1134 [==============================] - 630s 555ms/step - loss: 52.4856 - f1: 0.4685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7eef9b080128>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=30,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight = class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12096/12096 [==============================] - 169s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = (pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = []\n",
    "labels = train_generator.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(labels[index])\n",
    "    predictions2.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_test = test_df_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "      <th>keras_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>[Romance, Fiction]</td>\n",
       "      <td>9102.jpg</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34116</th>\n",
       "      <td>[History, Biography, Nonfiction]</td>\n",
       "      <td>34116.jpg</td>\n",
       "      <td>[Nonfiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53879</th>\n",
       "      <td>[Crime, Fiction, Mystery, Thriller]</td>\n",
       "      <td>53879.jpg</td>\n",
       "      <td>[Fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30327</th>\n",
       "      <td>[Childrens, Fantasy]</td>\n",
       "      <td>30327.jpg</td>\n",
       "      <td>[Nonfiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36487</th>\n",
       "      <td>[Young Adult, Fantasy]</td>\n",
       "      <td>36487.jpg</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                genres_cut  file_name    keras_pred\n",
       "9102                    [Romance, Fiction]   9102.jpg            []\n",
       "34116     [History, Biography, Nonfiction]  34116.jpg  [Nonfiction]\n",
       "53879  [Crime, Fiction, Mystery, Thriller]  53879.jpg     [Fiction]\n",
       "30327                 [Childrens, Fantasy]  30327.jpg  [Nonfiction]\n",
       "36487               [Young Adult, Fantasy]  36487.jpg            []"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_test['keras_pred'] = predictions2\n",
    "new_feature_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"test_with_weights.pickle\",\"wb\")\n",
    "pickle.dump(new_feature_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36298"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12096"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test set\n",
    "pickle_in_test = open(\"test_with_new_feature.pickle\",\"rb\")\n",
    "test2 = pickle.load(pickle_in_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
