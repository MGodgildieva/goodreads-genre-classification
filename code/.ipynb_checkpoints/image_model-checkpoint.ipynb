{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import urllib.request as req\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes F1 score\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes hamming loss\n",
    "def hn_multilabel_loss(y_true, y_pred):\n",
    "    # Avoid divide by 0\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Multi-task loss\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloads images from links in 'image_url' column\n",
    "def download_images(dataframe,out_folder):\n",
    "    ids = dataframe.index.values\n",
    "    for image_id in ids:\n",
    "        url = dataframe.loc[image_id]['image_url']\n",
    "        if os.path.isfile(out_folder + '/' + str(image_id) + '.jpg') == False:\n",
    "            r = req.urlretrieve(url, out_folder + '/' + str(image_id) + '.jpg')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return a collumn with names of downloaded images\n",
    "def return_image_name_col(df):\n",
    "    ids = df.index.values\n",
    "    names = []\n",
    "    for i in ids:\n",
    "        names.append(str(i)+'.jpg')\n",
    "    return np.array(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training set\n",
    "pickle_in_train = open(\"all_books_train.pickle\",\"rb\")\n",
    "train = pickle.load(pickle_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test set\n",
    "pickle_in_test = open(\"all_books_test.pickle\",\"rb\")\n",
    "test = pickle.load(pickle_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36389, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12131, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_edition</th>\n",
       "      <th>book_format</th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>book_pages</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_rating_count</th>\n",
       "      <th>book_review_count</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>image_url</th>\n",
       "      <th>genres_list</th>\n",
       "      <th>genres_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>Nicole Jacquelyn</td>\n",
       "      <td>\"How is it, that someone can make decision aft...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305 pages</td>\n",
       "      <td>4.02</td>\n",
       "      <td>17962</td>\n",
       "      <td>1159</td>\n",
       "      <td>Craving Constellations</td>\n",
       "      <td>Romance|Romance|Contemporary Romance|Contemporary</td>\n",
       "      <td>https://images.gr-assets.com/books/1377563339l...</td>\n",
       "      <td>[Romance, Contemporary, Contemporary Romance]</td>\n",
       "      <td>[Romance, Contemporary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19880</th>\n",
       "      <td>Adam Schell</td>\n",
       "      <td>A village in Tuscany is the setting for this j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78039E+12</td>\n",
       "      <td>340 pages</td>\n",
       "      <td>3.74</td>\n",
       "      <td>646</td>\n",
       "      <td>161</td>\n",
       "      <td>Tomato Rhapsody: A Fable of Love, Lust &amp; Forbi...</td>\n",
       "      <td>Fiction|Historical|Historical Fiction|Cultural...</td>\n",
       "      <td>https://images.gr-assets.com/books/1320422913l...</td>\n",
       "      <td>[Historical Fiction, Fiction, Food and Drink, ...</td>\n",
       "      <td>[Fiction, Romance, Historical, Cultural]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>Robert Moss</td>\n",
       "      <td>Have you ever said something was “only a dream...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78158E+12</td>\n",
       "      <td>224 pages</td>\n",
       "      <td>4.04</td>\n",
       "      <td>345</td>\n",
       "      <td>41</td>\n",
       "      <td>The Three \"Only\" Things: Tapping the Power of ...</td>\n",
       "      <td>Nonfiction|Spirituality|Psychology|Spiritualit...</td>\n",
       "      <td>https://images.gr-assets.com/books/1328746102l...</td>\n",
       "      <td>[Nonfiction, New Age, Psychology, Spirituality]</td>\n",
       "      <td>[Nonfiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>David Ambrose</td>\n",
       "      <td>A train of seemingly random events - coinciden...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Binding</td>\n",
       "      <td>9.78074E+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.35</td>\n",
       "      <td>166</td>\n",
       "      <td>18</td>\n",
       "      <td>Coincidence</td>\n",
       "      <td>Fiction|Suspense|Historical|Science Fiction|My...</td>\n",
       "      <td>https://images.gr-assets.com/books/1408924887l...</td>\n",
       "      <td>[Suspense, Fiction, Mystery, Historical, Scien...</td>\n",
       "      <td>[Fiction, Mystery, Historical, Science Fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>Richard North Patterson</td>\n",
       "      <td>When the body of eleven-year-old Thuy Sen is f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78035E+12</td>\n",
       "      <td>463 pages</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2400</td>\n",
       "      <td>154</td>\n",
       "      <td>Conviction</td>\n",
       "      <td>Fiction|Mystery|Thriller|Legal Thriller|Thriller</td>\n",
       "      <td>https://images.gr-assets.com/books/1399495278l...</td>\n",
       "      <td>[Thriller, Legal Thriller, Fiction, Mystery]</td>\n",
       "      <td>[Thriller, Fiction, Mystery]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  book_authors  \\\n",
       "6377          Nicole Jacquelyn   \n",
       "19880              Adam Schell   \n",
       "23352              Robert Moss   \n",
       "16021            David Ambrose   \n",
       "49981  Richard North Patterson   \n",
       "\n",
       "                                               book_desc book_edition  \\\n",
       "6377   \"How is it, that someone can make decision aft...          NaN   \n",
       "19880  A village in Tuscany is the setting for this j...          NaN   \n",
       "23352  Have you ever said something was “only a dream...          NaN   \n",
       "16021  A train of seemingly random events - coinciden...          NaN   \n",
       "49981  When the body of eleven-year-old Thuy Sen is f...          NaN   \n",
       "\n",
       "           book_format    book_isbn book_pages  book_rating  \\\n",
       "6377    Kindle Edition          NaN  305 pages         4.02   \n",
       "19880        Hardcover  9.78039E+12  340 pages         3.74   \n",
       "23352        Hardcover  9.78158E+12  224 pages         4.04   \n",
       "16021  Unknown Binding  9.78074E+12        NaN         3.35   \n",
       "49981        Hardcover  9.78035E+12  463 pages         3.89   \n",
       "\n",
       "       book_rating_count  book_review_count  \\\n",
       "6377               17962               1159   \n",
       "19880                646                161   \n",
       "23352                345                 41   \n",
       "16021                166                 18   \n",
       "49981               2400                154   \n",
       "\n",
       "                                              book_title  \\\n",
       "6377                              Craving Constellations   \n",
       "19880  Tomato Rhapsody: A Fable of Love, Lust & Forbi...   \n",
       "23352  The Three \"Only\" Things: Tapping the Power of ...   \n",
       "16021                                        Coincidence   \n",
       "49981                                         Conviction   \n",
       "\n",
       "                                                  genres  \\\n",
       "6377   Romance|Romance|Contemporary Romance|Contemporary   \n",
       "19880  Fiction|Historical|Historical Fiction|Cultural...   \n",
       "23352  Nonfiction|Spirituality|Psychology|Spiritualit...   \n",
       "16021  Fiction|Suspense|Historical|Science Fiction|My...   \n",
       "49981   Fiction|Mystery|Thriller|Legal Thriller|Thriller   \n",
       "\n",
       "                                               image_url  \\\n",
       "6377   https://images.gr-assets.com/books/1377563339l...   \n",
       "19880  https://images.gr-assets.com/books/1320422913l...   \n",
       "23352  https://images.gr-assets.com/books/1328746102l...   \n",
       "16021  https://images.gr-assets.com/books/1408924887l...   \n",
       "49981  https://images.gr-assets.com/books/1399495278l...   \n",
       "\n",
       "                                             genres_list  \\\n",
       "6377       [Romance, Contemporary, Contemporary Romance]   \n",
       "19880  [Historical Fiction, Fiction, Food and Drink, ...   \n",
       "23352    [Nonfiction, New Age, Psychology, Spirituality]   \n",
       "16021  [Suspense, Fiction, Mystery, Historical, Scien...   \n",
       "49981       [Thriller, Legal Thriller, Fiction, Mystery]   \n",
       "\n",
       "                                            genres_cut  \n",
       "6377                           [Romance, Contemporary]  \n",
       "19880         [Fiction, Romance, Historical, Cultural]  \n",
       "23352                                     [Nonfiction]  \n",
       "16021  [Fiction, Mystery, Historical, Science Fiction]  \n",
       "49981                     [Thriller, Fiction, Mystery]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show training data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download training images\n",
    "#download_images(train,\"train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download test images\n",
    "#download_images(test, \"test_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename_col = return_image_name_col(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[['genres_cut']]\n",
    "train_df['file_name'] = train_filename_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>[Romance, Contemporary]</td>\n",
       "      <td>6377.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19880</th>\n",
       "      <td>[Fiction, Romance, Historical, Cultural]</td>\n",
       "      <td>19880.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>[Nonfiction]</td>\n",
       "      <td>23352.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>[Fiction, Mystery, Historical, Science Fiction]</td>\n",
       "      <td>16021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>[Thriller, Fiction, Mystery]</td>\n",
       "      <td>49981.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            genres_cut  file_name\n",
       "6377                           [Romance, Contemporary]   6377.jpg\n",
       "19880         [Fiction, Romance, Historical, Cultural]  19880.jpg\n",
       "23352                                     [Nonfiction]  23352.jpg\n",
       "16021  [Fiction, Mystery, Historical, Science Fiction]  16021.jpg\n",
       "49981                     [Thriller, Fiction, Mystery]  49981.jpg"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_cut</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>[Romance, Fiction]</td>\n",
       "      <td>9102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34116</th>\n",
       "      <td>[History, Biography, Nonfiction]</td>\n",
       "      <td>34116.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53879</th>\n",
       "      <td>[Crime, Fiction, Mystery, Thriller]</td>\n",
       "      <td>53879.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30327</th>\n",
       "      <td>[Childrens, Fantasy]</td>\n",
       "      <td>30327.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36487</th>\n",
       "      <td>[Young Adult, Fantasy]</td>\n",
       "      <td>36487.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                genres_cut  file_name\n",
       "9102                    [Romance, Fiction]   9102.jpg\n",
       "34116     [History, Biography, Nonfiction]  34116.jpg\n",
       "53879  [Crime, Fiction, Mystery, Thriller]  53879.jpg\n",
       "30327                 [Childrens, Fantasy]  30327.jpg\n",
       "36487               [Young Adult, Fantasy]  36487.jpg"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filename_col = return_image_name_col(test)\n",
    "test_df = test[['genres_cut']]\n",
    "test_df['file_name'] = test_filename_col\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the image downloading the website fall and some images have turned not valid for training. \n",
    "\n",
    "train_df_valid, test_df_valid - datasets containing only valid images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_valid = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in train_df.iterrows():\n",
    "    path = 'train_images/' + row['file_name']\n",
    "    if os.stat(path).st_size < 1024:\n",
    "        train_df_valid.drop(index = index,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36298, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_valid = test_df.copy()\n",
    "for index,row in test_df.iterrows():\n",
    "    path = 'test_images/' + row['file_name']\n",
    "    if os.stat(path).st_size < 1024:\n",
    "        test_df_valid.drop(index = index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12096, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_out = open(\"train_images_valid.pickle\",\"wb\")\n",
    "#pickle.dump(train_df_valid, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_out = open(\"test_images_valid.pickle\",\"wb\")\n",
    "#pickle.dump(test_df_valid, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = np.unique(list(itertools.chain.from_iterable(train_df['genres_cut'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulid the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(100,100,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('tahn'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(23, activation='sigmoid'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=[hn_multilabel_loss],metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(),\n",
    "            EarlyStopping(patience=4),\n",
    "            ModelCheckpoint(filepath='model.h5', save_best_only=True)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New train feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29038 validated image filenames belonging to 23 classes.\n",
      "Found 7260 validated image filenames.\n",
      "Epoch 1/30\n",
      "907/907 [==============================] - 892s 984ms/step - loss: 7.9220 - f1: 0.2050\n",
      "Epoch 2/30\n",
      "907/907 [==============================] - 884s 975ms/step - loss: 7.5742 - f1: 0.2254\n",
      "Epoch 3/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 7.4137 - f1: 0.2473\n",
      "Epoch 4/30\n",
      "907/907 [==============================] - 884s 975ms/step - loss: 7.2842 - f1: 0.2625\n",
      "Epoch 5/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 7.1757 - f1: 0.2758\n",
      "Epoch 6/30\n",
      "907/907 [==============================] - 884s 975ms/step - loss: 7.0941 - f1: 0.2860\n",
      "Epoch 7/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 7.0001 - f1: 0.2989\n",
      "Epoch 8/30\n",
      "907/907 [==============================] - 886s 976ms/step - loss: 6.9147 - f1: 0.3107\n",
      "Epoch 9/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 6.8383 - f1: 0.3199\n",
      "Epoch 10/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 6.7584 - f1: 0.3304\n",
      "Epoch 11/30\n",
      "907/907 [==============================] - 884s 975ms/step - loss: 6.6754 - f1: 0.3432\n",
      "Epoch 12/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 6.6005 - f1: 0.3517\n",
      "Epoch 13/30\n",
      "907/907 [==============================] - 887s 978ms/step - loss: 6.5137 - f1: 0.3644\n",
      "Epoch 14/30\n",
      "907/907 [==============================] - 885s 975ms/step - loss: 6.4558 - f1: 0.3737\n",
      "Epoch 15/30\n",
      "907/907 [==============================] - 885s 975ms/step - loss: 6.3861 - f1: 0.3820\n",
      "Epoch 16/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 6.3099 - f1: 0.3943\n",
      "Epoch 17/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 6.2419 - f1: 0.4015\n",
      "Epoch 18/30\n",
      "907/907 [==============================] - 884s 975ms/step - loss: 6.1828 - f1: 0.4129\n",
      "Epoch 19/30\n",
      "907/907 [==============================] - 884s 975ms/step - loss: 6.1421 - f1: 0.4214\n",
      "Epoch 20/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 6.0776 - f1: 0.4292\n",
      "Epoch 21/30\n",
      "907/907 [==============================] - 884s 975ms/step - loss: 6.0419 - f1: 0.4377\n",
      "Epoch 22/30\n",
      "907/907 [==============================] - 883s 974ms/step - loss: 6.0369 - f1: 0.4392\n",
      "Epoch 23/30\n",
      "907/907 [==============================] - 885s 975ms/step - loss: 5.9942 - f1: 0.4445\n",
      "Epoch 24/30\n",
      "907/907 [==============================] - 883s 974ms/step - loss: 5.9860 - f1: 0.4492\n",
      "Epoch 25/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 5.9479 - f1: 0.4541\n",
      "Epoch 26/30\n",
      "907/907 [==============================] - 886s 977ms/step - loss: 5.9520 - f1: 0.4555\n",
      "Epoch 27/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 5.9340 - f1: 0.4578\n",
      "Epoch 28/30\n",
      "907/907 [==============================] - 887s 977ms/step - loss: 5.9174 - f1: 0.4629\n",
      "Epoch 29/30\n",
      "907/907 [==============================] - 882s 973ms/step - loss: 5.9314 - f1: 0.4619\n",
      "Epoch 30/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 5.9123 - f1: 0.4666\n",
      "7260/7260 [==============================] - 192s 26ms/step\n",
      "Found 29038 validated image filenames belonging to 23 classes.\n",
      "Found 7260 validated image filenames.\n",
      "Epoch 1/30\n",
      "907/907 [==============================] - 854s 941ms/step - loss: 6.4098 - f1: 0.4068\n",
      "Epoch 2/30\n",
      "907/907 [==============================] - 882s 972ms/step - loss: 6.4039 - f1: 0.4057\n",
      "Epoch 3/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 6.3821 - f1: 0.4069\n",
      "Epoch 4/30\n",
      "907/907 [==============================] - 885s 976ms/step - loss: 6.3583 - f1: 0.4103\n",
      "Epoch 5/30\n",
      "907/907 [==============================] - 884s 974ms/step - loss: 6.3543 - f1: 0.4103\n",
      "Epoch 6/30\n",
      "907/907 [==============================] - 882s 972ms/step - loss: 6.3301 - f1: 0.4168\n",
      "Epoch 7/30\n",
      "907/907 [==============================] - 920s 1s/step - loss: 6.3213 - f1: 0.4151\n",
      "Epoch 8/30\n",
      "907/907 [==============================] - 1022s 1s/step - loss: 6.2992 - f1: 0.4181\n",
      "Epoch 9/30\n",
      "190/907 [=====>........................] - ETA: 16:34 - loss: 6.2861 - f1: 0.4270"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-63109ae31965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m#prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Predict genres for every of 5 folds and save the predictions\n",
    "# in predictions_lst\n",
    "for train_index, test_index in kf.split(train_df_valid):\n",
    "    #print(train_index,test_index)\n",
    "    #train generator\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_valid.iloc[train_index],\n",
    "    directory=\"train_images\",\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"genres_cut\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=list(all_classes),\n",
    "    target_size=(100,100))\n",
    "    \n",
    "    #test generator \n",
    "    test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_valid.iloc[test_index],\n",
    "    directory=\"train_images\",\n",
    "    x_col=\"file_name\",\n",
    "    y_col=None,\n",
    "    batch_size=1,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(100,100))\n",
    "    \n",
    "    #fitting the model\n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=10,\n",
    "                    callbacks=callbacks)\n",
    "    #prediction\n",
    "    test_generator.reset()\n",
    "    pred=model.predict_generator(test_generator,\n",
    "    steps=STEP_SIZE_TEST,\n",
    "    verbose=1)\n",
    "    \n",
    "    pred_bool = (pred > 0.5)\n",
    "    \n",
    "\n",
    "    predictions = []\n",
    "    labels = train_generator.class_indices\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    for row in pred_bool:\n",
    "        l=[]\n",
    "        for index,cls in enumerate(row):\n",
    "            if cls:\n",
    "                l.append(labels[index])\n",
    "        predictions.append(l)\n",
    "    predictions_lst.extend(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train = train_df_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset with new feature to use it for stacking later\n",
    "new_feature_train['keras_pred'] = predictions_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving new dataset to pikle file\n",
    "pickle_out = open(\"train_with_new_feature2.pickle\",\"wb\")\n",
    "pickle.dump(new_feature_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New test feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train_df_valid,\n",
    "directory=\"train_images\",\n",
    "x_col=\"file_name\",\n",
    "y_col=\"genres_cut\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "classes=list(all_classes),\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_df_valid,\n",
    "directory=\"test_images\",\n",
    "x_col=\"file_name\",\n",
    "y_col=None,\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traing the model on all training set \n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=10,\n",
    "                    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = (pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions for the test set\n",
    "predictions2 = []\n",
    "labels = train_generator.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(labels[index])\n",
    "    predictions2.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_test = test_df_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make test dataset with new feature\n",
    "new_feature_test['keras_pred'] = predictions2\n",
    "new_feature_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new dataset to pickle file\n",
    "pickle_out = open(\"test_with_new_feature2.pickle\",\"wb\")\n",
    "pickle.dump(new_feature_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
